{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "\n",
    "from scipy import sparse as sp\n",
    "from scipy import sparse\n",
    "from scipy.sparse import spdiags\n",
    "from scipy.sparse import linalg\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from scipy.io import savemat,loadmat\n",
    "import scipy.integrate as integrate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import product\n",
    "from sklearn.decomposition import SparseCoder\n",
    "from tqdm.notebook import tqdm,trange\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import pysindy as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 19 08:46:02 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.95.01    Driver Version: 440.95.01    CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000004:04:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    53W / 300W |    706MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000004:05:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    52W / 300W |  14915MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000035:03:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    52W / 300W |    438MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000035:04:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    54W / 300W |    438MiB / 16160MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discover Latent Space Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 4\n",
    "# ### Load Data if Model Already Exists ###\n",
    "snapshot_full = pickle.load(open(\"./data/snapshot_full.p\", 'rb'))\n",
    "snapshot_full = snapshot_full[:,:-1].astype('float32')\n",
    "snapshot_full_FOM = pickle.load(open(\"./data/FOM.p\",'rb'))\n",
    "snapshot_full_FOM = snapshot_full_FOM.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/g15/fries4/GitHub/NM-ROM/nm-rom/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /g/g15/fries4/GitHub/NM-ROM/pytorch/c10/cuda/CUDAFunctions.cpp:104.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Set print option\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Choose device that is not being used\n",
    "gpu_ids = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAABBCAYAAADCOJOUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAACzxJREFUeJzt3X2MXFUZx/Hvw9YWqEBbW3EpaNuUGGqN0G6aFpRgwb6BFBOIVEIrL2mixKhotA1/EDWKiDFIMEBDi9VUpPIilVAL4UXCP5Vt0VJoS7e8lIXSbi3l1UjRxz/OM+1lOzM7uzO7c2f290k2e+fcM3fPs2d2np17zj3X3B0REZGeHFHvBoiISGNQwhARkYooYYiISEWUMEREpCJKGCIiUhElDBERqUhuE4aZzTGzbWbWYWZL6t2eSpjZSWb2mJltMbNnzezbUT7KzB42s+3xfWSUm5ndFDFuMrMpmWMtivrbzWxRvWIqxsxazOxpM3sgHo83s/XR1rvMbGiUD4vHHbF/XOYYS6N8m5nNrk8khzOzEWZ2t5ltjX6c0Sz9Z2bfjdflZjO708yObOS+M7MVZrbHzDZnymrWV2Y21cyeiefcZGaWg/huiNfmJjO7z8xGZPYV7ZdS76Wl+r4sd8/dF9AC7AAmAEOBfwKT6t2uCtrdCkyJ7WOA54FJwC+AJVG+BLg+tucBawEDpgPro3wU8EJ8HxnbI+sdXybOq4E/AA/E49XAxbF9K/CN2P4mcGtsXwzcFduTok+HAeOjr1vqHVe0bSVwZWwPBUY0Q/8BY4EXgaMyffb1Ru474ExgCrA5U1azvgL+DsyI56wF5uYgvlnAkNi+PhNf0X6hzHtpqb4v26Z6vojL/KJmAOsyj5cCS+vdrj7EcT/wJWAb0BplrcC22L4NWJCpvy32LwBuy5R/qF6dYzoReASYCTwQf0x7My/ig30HrANmxPaQqGfd+zNbr86xHUt6U7Vu5Q3ff6SE8Uq8MQ6Jvpvd6H0HjOv2hlqTvop9WzPlH6pXr/i67fsKsCq2i/YLJd5Ly/3dlvvK6ympwou7oDPKGkZ8hD8NWA8c7+67AOL7x6NaqTjzHP+NwA+A/8XjjwH73f2DeJxt68E4Yv+bUT+v8U0AuoA74pTb7WY2nCboP3d/FfglsBPYReqLDTRP3xXUqq/Gxnb38jy5nPTJB3ofX7m/25LymjCKnStsmDVMzOyjwD3Ad9z9rXJVi5R5mfK6MrPzgD3uviFbXKSq97Avl/GR/pOeAtzi7qcB75JOa5TSMPHFufz5pNMVJwDDgblFqjZq3/Wkt/HkOk4zuwb4AFhVKCpSrebx5TVhdAInZR6fCLxWp7b0ipl9hJQsVrn7vVG828xaY38rsCfKS8WZ1/jPAM43s5eAP5JOS90IjDCzIVEn29aDccT+44B95De+TqDT3dfH47tJCaQZ+u8c4EV373L3A8C9wOk0T98V1KqvOmO7e3ndxcD8ecAlHueT6H18eynd9yXlNWE8BZwco/hDSYNua+rcph7FLIrlwBZ3/1Vm1xqgMPtiEWlso1C+MGZwTAfejI/R64BZZjYy/jOcFWV15e5L3f1Edx9H6pNH3f0S4DHgwqjWPb5C3BdGfY/yi2MmznjgZNIAY125++vAK2b26Sg6G3iO5ui/ncB0Mzs6XqeF2Jqi7zJq0lex720zmx6/r4WZY9WNmc0Bfgic7+7vZXaV6pei76XRl6X6vrR6DVZVMNgzjzTLaAdwTb3bU2GbP0/6WLcJ+Ed8zSOdL3wE2B7fR0V9A34TMT4DtGWOdTnQEV+X1Tu2IrGexaFZUhPixdkB/AkYFuVHxuOO2D8h8/xrIu5tDPDskx7iOhVojz78M2nmTFP0H/AjYCuwGfg9aUZNw/YdcCdpPOYA6T/pK2rZV0Bb/K52ADfTbTJEneLrII1JFN5fbu2pXyjxXlqq78t9WTxRRESkrLyekhIRkZxRwhARkYooYYiISEWUMEREpCIDnjBKLYQlIiL5NqAJw8xaSFPb5pIWy1pgZpPK1F88UG2rB8XXuJo5NlB8jaw/YxvoTxjTgA53f8Hd3yddLTy/TP2m7dSg+BpXM8cGiq+RNU3CyPvCZSIiUsKAXrhnZhcBs939ynh8KTDN3b+VqbOYyJDDhg2bOnny5MOOs2HDBqZOnTowje5HXV1djBkzpt7N6DfNHF8zxwaKr5F1dXWxc+fOve5e8wCH9FylpnpcuMzdlwHLANra2ry9vb3qH2pm6Ip2ERkszOzl/jhun09JWR9uRwp8DZgZz5nGAC0q2NtkMcB3YhQRaQjVjGF8AHzP3U8h3fLwqpjxtAR4xN1PJi3+VZg6OxeYSBrkHg48Aax292eraEO/UIIRETlcnxOGu+9y942x/TawhTSAPZ90X2Ti+wWxPR/4nbs/6O6fBF4GVvT15+dJbxKMkouINKqazJKq8nakg0pfxlKUZEQkD6pOGDW4HWn34y02s3Yza+/q6qq2eU1Bp8hEJA+qShiZ25EeT7oJCcA+M9sYg973c+gWia8BN8SSIOuBcRS5JaC7L3P3Nndva9Zpb/1Np8hEpD9UM0uqcDvSI0kD2AXvA1tj0Pt40lhFoXws6daBfwFGFE5dSf3o04uIVKqa6zDOAC4F3iElgjFmNg8YA3zCzLYD+4GWqD+RQ7cDfA9oMTNzXSDRUPqSYNTFIs2hzwnD3Z80s3uA64BjgO+TEsIb7j4T0rUawNp4ylhgjrt3xr4dpPvv7u178yXvlGBEmkc1p6TOA/a4+4ZscZGqXsG+7HE16D2I6RSZSH5VM+h9BnC+mb1EWnV2JnAjMMLMCp9cskt/HFwWJPYfB+zrflANektvKMGIDJxqLtxbCkwG2kkD2v8FbgaeBDbGGMZq4KF4yhpgmZl1ADuAjRq/kIGmBCPSd9Veh/Fr4K/AQtJMqS3AbmAk6RTUG0Br1O0ERsf2Oxy6oE8kt5RgRA6pZgzjWOBMYLm7P+7u57r7fuAs0pLlE4HZwJfjKfOAq919ort/BjjKzFqLHVukUSnBSDOr5hPGBKALuMPMnjaz281sOFoaRKRiSjDSSKpJGEOAKcAt7n4a8C6HVqYtRrOkRKqkBCP1VM2Fe53AW8AKM3PgdeAAsTQI6dqM5zh8aZAxwL9I4xlFlwYhcwOlKtonMujpOhippWo+YbQARwML3H0yaXDb0dIgIg1Ln2CknGpnSe0HVprZJtJV28v58NIgLRRfGuSrxNIgVf58EakjJZjBpZqlQV41s+uAnwL/Jl1v8Te0NIiIlNDblZR1eixfqplWO5J0F73xwAmk267OLVJVS4OISK/p00v+VHNK6hzgRXfvcvcDwL3A6WhpEBGpA93Nsv/1eErKzFYAhYUGJ0fZKNLqtKfG7VkvBM4mLRPyBtBpZnuA54H741C7gbVm1gU8DDyqpUFEpJ40i6x3KvmE8VtgTreyJcB9wM+Bz5ISwxGkGVGvAjtJy4N8EVgeCeYLwOOkQfDLgZ9V3XoRkQE02O9m2WPCcPcnOPzU0XxgpbtfC3wO2OfulwLnAre5+zR3P4k0oD2KtETIQ+5+gbtPAFYCp9QwDhGRXGnGMZi+jmH0dvkPLQsiIlJGIySYaq70LqbUTKiKZkhBmiUFLI6H/zGzzTVqWx6NprmnFTdzfM0cGyi+hlAiaYwGPtUfP6+vCWO3mbW6+65Ycbaw/MfBmVChMEuqk7SKbbb88WIHzi4NYmbt7t7WxzbmnuJrXM0cGyi+RhaxjeuPY/f1lNQaYFFsL+LQTKg1wEJLpgNvximrdcAsMxsZ12/MijIREWkQlUyrvZP06WC0mXUC15JmR602sytIM6IuiuoPku570QG8B1wG4O77zOwnwFNR78fuftg1GCIikl89Jgx3X1Bi19lF6jpwVYnjrABW9Kp1cWqqiSm+xtXMsYHia2T9FpsN5otQRESkctWuVisiIoOEEoaIiFRECUNERCqihCEiIhVRwhARkYooYYiISEWUMEREpCL/B63VaXZYg5RbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = torch.load('./model/AE_gauss.tar', map_location=device)    \n",
    "\n",
    "maxk = 10\n",
    "convergence_threshold = 1.0e-8\n",
    "\n",
    "nx = 1001\n",
    "dx = 6 / (nx - 1)\n",
    "nt = 1000\n",
    "tstop = 1\n",
    "x=np.linspace(-3, 3, nx)\n",
    "\n",
    "dt = tstop / nt \n",
    "c = dt/dx\n",
    "t = np.linspace(0, tstop, nt)\n",
    "\n",
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y\n",
    "m = 1000\n",
    "f = 5\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m\n",
    " \n",
    "\n",
    "encoder = Encoder(m,M1,f).to(device)\n",
    "decoder = Decoder(f,M2,m).to(device)\n",
    "\n",
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask\n",
    "\n",
    "# Prune\n",
    "mask = create_mask_v2(m,b,db)\n",
    "prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "# optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "\n",
    "loss_func = nn.MSELoss(reduction='mean')\n",
    "\n",
    "encoder.load_state_dict(model['encoder_state_dict'])\n",
    "decoder.load_state_dict(model['decoder_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'product' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f5eab7ec2025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwidth_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamp_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'product' is not defined"
     ]
    }
   ],
   "source": [
    "amp_arr = np.array([.7,.9])\n",
    "width_arr = np.array([.9,1.1])\n",
    "\n",
    "P = list(product(amp_arr, width_arr))\n",
    "P = np.array(P)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax_u = plt.axes()\n",
    "ax_u.set_title('Latent Space of U')\n",
    "latent_space_SS = []\n",
    "\n",
    "ndata = snapshot_full.shape[0]\n",
    "nset = int(ndata/(nt+1))\n",
    "\n",
    "colors = ['b','m','y','g','c','r']\n",
    "styles = ['-', '--', ':', '-.', (0, (3, 5, 1, 5, 1, 5))]\n",
    "for foo in range(nset):\n",
    "    input_SS=torch.tensor(snapshot_full[foo*(nt+1):(foo+1)*(nt+1)].astype('float32')).to(device)\n",
    "    latent_space = encoder(input_SS).cpu().detach().numpy()\n",
    "#     latent_space_SS.append(latent_space)\n",
    "    latent_space_SS.append(np.column_stack([latent_space,P[foo,0]*np.ones(nt+1),P[foo,1]*np.ones(nt+1)]))\n",
    "    for i in range(5):\n",
    "        if i == 0:\n",
    "            ax_u.plot(latent_space[:,i], linestyle = styles[i], color = colors[foo])\n",
    "        else:\n",
    "            ax_u.plot(latent_space[:,i], linestyle = styles[i], color = colors[foo])\n",
    "\n",
    "pickle.dump(latent_space_SS, open('./data/latent_space_SS.p', 'wb'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 1\n",
    "# normal = np.amax(np.abs(latent_space_SS))\n",
    "normal = 1\n",
    "data = list(latent_space_SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_library = ps.PolynomialLibrary(include_interaction=False, degree = degree)\n",
    "model_PS = ps.SINDy(feature_library = poly_library)\n",
    "model_PS.fit(data, t = dt, multiple_trajectories = True)\n",
    "model_PS.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dynamics on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Max_Error = 0\n",
    "for i in range(len(data)):\n",
    "    X_sim = model_PS.simulate(data[i][0], t)\n",
    "    Error = LA.norm((X_sim-data[i][:-1])**2/np.prod(X_sim.shape))\n",
    "    if Error > Max_Error:\n",
    "        Max_Error = Error\n",
    "    print(\"MSE for Simulation {}: {}\".format(i, Error))\n",
    "print(\"\")\n",
    "print('Max MSE: {}'.format(Max_Error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.suptitle('Latent-Space Dynamics and Discovered Trajectory')\n",
    "ax = plt.axes()\n",
    "\n",
    "for i in [-1]:\n",
    "    ax.plot(t,data[i][:-1], alpha = .5)\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "ax.plot(t,X_sim,'--')\n",
    "labels = ['Original', '_nolegend','_nolegend','_nolegend','_nolegend', 'Discovered Dynamics']\n",
    "ax.legend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = np.empty([len(data),f])\n",
    "# for i in range(len(data)):\n",
    "#     L[i,:] = data[i][0]\n",
    "\n",
    "# B = LA.lstsq(P, L, rcond = None)[0].T\n",
    "\n",
    "L = np.empty([len(data),f+2])\n",
    "for i in range(len(data)):\n",
    "    L[i,:] = data[i][0]\n",
    "\n",
    "B = LA.lstsq(P, L, rcond = None)[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_full_FOM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dynamics on FOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_FOM = encoder(torch.tensor(snapshot_full_FOM[:,:-1]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_arr_FOM = np.array([0.8])\n",
    "width_arr_FOM = np.array([1.0])\n",
    "# IC_guess = np.matmul(B, np.array([amp_arr_FOM,width_arr_FOM])).reshape(f)\n",
    "IC_guess = np.matmul(B, np.array([amp_arr_FOM,width_arr_FOM])).reshape(f+2)\n",
    "IC_real = latent_space_FOM[0]\n",
    "# print('Initial Condition Error: {}'.format(LA.norm(IC_guess-IC_real.cpu().detach().numpy()/normal)))\n",
    "IC_guess.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_FOM_recon = torch.tensor(normal*model_PS.simulate(IC_guess, t).astype('float32')).to(device)\n",
    "# FOM_recon = decoder(latent_space_FOM_recon).cpu().detach().numpy()\n",
    "FOM_recon = decoder(latent_space_FOM_recon[:,:-2]).cpu().detach().numpy()\n",
    "print('Final Position Error: {:.3}%'.format(LA.norm(FOM_recon[-1]-snapshot_full_FOM[-2,:-1])/LA.norm(snapshot_full_FOM[-2,:-1])*100))\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "fig.suptitle('Reconstruction of FOM from SALDI')\n",
    "ax.set_title('Relative Error: {:.3}%'.format(LA.norm(FOM_recon[-1]-snapshot_full_FOM[-2,:-1])/LA.norm(snapshot_full_FOM[-2,:-1])*100))\n",
    "ax.plot(x[:],snapshot_full_FOM[-1], label = 'FOM')\n",
    "ax.plot(x[:-1], FOM_recon[-1],'--', label = 'SALDI')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOM_re = np.empty(nt)\n",
    "for i in range(nt):\n",
    "    FOM_re[i] = LA.norm(FOM_recon[i]-snapshot_full_FOM[i,:-1])/LA.norm(snapshot_full_FOM[i,:-1])\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Relative Error for FOM reconstruction via SALDI')\n",
    "ax = plt.axes()\n",
    "ax.set_title('Max Relative Error: {:.3}%'.format(np.amax(FOM_re)*100))\n",
    "ax.plot(t, FOM_re*100)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Relative Error (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA.norm(FOM_recon[-1]-snapshot_full_FOM[-2,:-1])/LA.norm(snapshot_full_FOM[-2,:-1])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_full_FOM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxk = 10\n",
    "convergence_threshold = 1.0e-8\n",
    "\n",
    "nx = 1001\n",
    "dx = 6 / (nx - 1)\n",
    "nt = 1000\n",
    "tstop = 1\n",
    "x=np.linspace(-3, 3, nx)\n",
    "\n",
    "dt = tstop / nt \n",
    "c = dt/dx\n",
    "t = np.linspace(0, tstop, nt)\n",
    "# ## Functions\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "def kth_diag_indices(a, k):\n",
    "    rows, cols = np.diag_indices_from(a)\n",
    "    if k < 0:\n",
    "        return rows[-k:], cols[:k]\n",
    "    elif k > 0:\n",
    "        return rows[:-k], cols[k:]\n",
    "    else:\n",
    "        return rows, cols\n",
    "\n",
    "def gaussian(amp,width):\n",
    "    \n",
    "    u0 = amp*np.exp(-(x-0.0)**2/(2*width**2))\n",
    "    u0[-1] = u0[0]\n",
    "    \n",
    "    return u0\n",
    "\n",
    "def residual(un,uw,c,idxn1):\n",
    "    \n",
    "    # r = -u^{n} + u^{n+1} -dt*f(u^{n+1})\n",
    "    \n",
    "    f = c*(uw**2 - uw*uw[idxn1]) \n",
    "    \n",
    "    r = -un + uw + f\n",
    "    \n",
    "    return r\n",
    "\n",
    "def jacobian(u,c,idxn1):\n",
    "\n",
    "    # J = I - dt*dfdu\n",
    "    \n",
    "    diag_comp = 1.0 + c*(2*u - u[idxn1])\n",
    "    subdiag_comp = np.ones(nx-1)\n",
    "    subdiag_comp[:-1] = -c*u[1:]\n",
    "        \n",
    "    data = np.array([diag_comp, subdiag_comp])\n",
    "    J = spdiags(data,[0,-1],nx-1,nx-1,format='csr')\n",
    "    J[0,-1] = -c*u[0]\n",
    "    \n",
    "    return J\n",
    "\n",
    "def solve(u0):\n",
    "\n",
    "    u = np.zeros((nt+1,nx))\n",
    "    u_inter=np.array([])\n",
    "    u[0] = u0\n",
    "    u_inter=np.append(u_inter,u0[:-1])\n",
    "    I = sparse.eye(nx,format='csr')\n",
    "    for n in range(nt): \n",
    "        uw = u[n,:-1].copy()\n",
    "        r = residual(u[n,:-1],uw,c,idxn1)\n",
    "        \n",
    "        for k in range(maxk):\n",
    "            J = jacobian(uw,c,idxn1)\n",
    "            duw = spsolve(J, -r)\n",
    "#             duw = np.linalg.solve(J,-r)\n",
    "            uw = uw + duw\n",
    "            r = residual(u[n,:-1],uw,c,idxn1)\n",
    "            u_inter=np.append(u_inter,uw)\n",
    "\n",
    "            rel_residual = np.linalg.norm(r)/np.linalg.norm(u[n,:-1])\n",
    "            if rel_residual < convergence_threshold:\n",
    "                u[n+1,:-1] = uw.copy()\n",
    "                u[n+1,-1] = u[n+1,0]\n",
    "                break\n",
    "    \n",
    "    return u,u_inter.reshape((-1,nx-1))\n",
    "\n",
    "def generate_dataset(amp_arr,width_arr):\n",
    "    \n",
    "    num_amp=amp_arr.shape[0]\n",
    "    num_width=width_arr.shape[0]\n",
    "    data = []\n",
    "    data_inter = []\n",
    "    for i in range(num_amp):\n",
    "        for j in range(num_width):\n",
    "            u0=gaussian(amp_arr[i],width_arr[j])\n",
    "#             u0=sine_wave(amp_arr[i],width_arr[j])\n",
    "            u,u_inter=solve(u0)\n",
    "            data.append(u)\n",
    "            data_inter.append(u_inter)\n",
    "    data = np.vstack(data)   \n",
    "    data_inter = np.vstack(data_inter)   \n",
    "    \n",
    "    return data, data_inter\n",
    "\n",
    "dn1=kth_diag_indices(np.eye(nx-1),-1)\n",
    "idxn1=np.zeros(nx-1,dtype='int')\n",
    "idxn1[1:]=np.arange(nx-2)\n",
    "idxn1[0]=nx-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_FOM_start = time.time()\n",
    "snapshot_full_FOM,snapshot_full_inter_FOM = generate_dataset(amp_arr_FOM,width_arr_FOM)\n",
    "time_FOM_stop = time.time()\n",
    "time_FOM = time_FOM_stop-time_FOM_start\n",
    "print('FOM time: {}'.format(time_FOM))\n",
    "\n",
    "time_SINDy_start = time.time()\n",
    "IC = np.matmul(B, np.array([amp_arr_FOM,width_arr_FOM])).reshape(f)\n",
    "latent_space_FOM_recon = torch.tensor(model_PS.simulate(IC, t).astype('float32')).to(device)\n",
    "FOM_recon = decoder(latent_space_FOM_recon).cpu().detach().numpy()\n",
    "time_SINDy_stop = time.time()\n",
    "time_SINDy = time_SINDy_stop-time_SINDy_start\n",
    "print('SINDy time: {}'.format(time_SINDy))\n",
    "print('')\n",
    "print('Relative Error: {}'.format(LA.norm(FOM_recon[-1]-snapshot_full_FOM[-1,:-1])/LA.norm(snapshot_full_FOM[-1,:-1])))\n",
    "print('')\n",
    "print('Speed Up: {}'.format(time_FOM/time_SINDy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NM-ROM",
   "language": "python",
   "name": "nm-rom"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
